# ğŸ“ Assistant IA AcadÃ©mique â€” RAG + Agents + Ollama + Streamlit

Assistant acadÃ©mique capable de :

- rÃ©pondre Ã  des questions Ã  partir de **documents internes** (RAG),
- effectuer des **calculs** (calculatrice sÃ©curisÃ©e),
- donner la **mÃ©tÃ©o**,
- faire des **recherches web** (avec consentement explicite ou dÃ©tection dâ€™actualitÃ©),
- gÃ©rer une **TODO-list persistante**,
- envoyer la **derniÃ¨re rÃ©ponse par e-mail**,
- discuter en **smalltalk** avec un modÃ¨le local Ollama.

Le tout est orchestrÃ© avec **Streamlit**, des outils maison dans `agents.py`, un **RAG lÃ©ger sans LLM**, et **Ollama** uniquement pour la partie conversationnelle.

---

## âœ… Objectifs pÃ©dagogiques (TP)

Ce projet illustre :

- un **RAG simple** basÃ© sur des fichiers texte locaux,
- des **agents / outils** (calculatrice, mÃ©tÃ©o, TODO, web),
- un **routage intelligent** (smalltalk / outils / RAG / web),
- une **mÃ©moire conversationnelle** persistante,
- une **interface conversationnelle** avec Streamlit,
- une **recherche web** avec demande de consentement,
- un **envoi dâ€™e-mails** via SMTP,
- un code structurÃ© et versionnÃ© (Git).

---

## ğŸ§  1. RAG interne (sans LLM)

**Fichier :** `rag_core.py`

### Principe

- On charge tous les fichiers **`.txt`** du dossier `RAG_Data/`.
- Chaque fichier est dÃ©coupÃ© en **sections Markdown** Ã  partir des lignes qui commencent par `##`.
- Chaque section devient un petit â€œdocumentâ€ avec :
  - `page_content` : titre + texte de la section,
  - `metadata["source"]` : chemin du fichier,
  - `metadata["section_title"]` : titre de la section.

### Recherche dâ€™une rÃ©ponse

Pour une question :

1. La question est **normalisÃ©e** (minuscules, accents enlevÃ©s, ponctuation simplifiÃ©e).
2. On essaie dâ€™abord de trouver une **section dont le titre correspond** Ã  la question :
   - soit le titre est contenu dans la question,
   - soit la question est contenue dans le titre.
3. Sinon, on calcule un **score combinÃ©** pour chaque section :
   - similaritÃ© floue entre le titre et la question,
   - nombre de mots-clÃ©s communs (normalisÃ©s).
4. On garde la meilleure section **seulement si le score est suffisant**  
   (pour Ã©viter de raconter nâ€™importe quoi).
5. Si aucune section nâ€™est jugÃ©e pertinente :
   - `answer = "La rÃ©ponse ne se trouve pas dans les documents internes."`
   - `source_documents = []`

ğŸ“Œ **Important :**  
Le RAG **ne fait appel Ã  aucun LLM**.  
La rÃ©ponse est un **extrait brut** de tes cours (`Cours_IA.txt`, `Cours_Python.txt`, `Cours_Reseaux.txt`, etc.).

---

## ğŸ¤– 2. Agents / Outils (`agents.py`)

Tous les outils renvoient du **texte prÃªt Ã  afficher** dans `app.py`.

---

### ğŸ§® 2.1. Calculatrice sÃ©curisÃ©e

- Analyse les expressions mathÃ©matiques via lâ€™AST Python (pas de `eval`).
- OpÃ©rations et fonctions autorisÃ©es :
  - `+`, `-`, `*`, `/`, `**`
  - `sqrt`, `sin`, `cos`, `tan`, `log`, `log10`, `exp`
  - constantes : `pi`, `e`

#### Expressions comprises

Exemples dâ€™expressions reconnues :

- `2 + 3 * 4`
- `2^8` â†’ `2**8`
- `2Â² + 3Â³`
- `sqrt16`, `log50`, `exp2`
- `sin45`, `cos30`, `tan60`  
  â†’ les angles sont interprÃ©tÃ©s en **degrÃ©s** puis convertis en radians :
  - `sin45` â†’ `sin(0,785398...)`
  - `sin 45Â°` ou `sin(45deg)` idem
- `e4` â†’ `e**4`
- `5(4*5)` â†’ `5*(4*5)` (multiplication implicite)

#### SÃ©curitÃ©

- Seuls certains types de nÅ“uds AST sont autorisÃ©s.
- Les noms non autorisÃ©s lÃ¨vent une erreur (`Symbole non autorisÃ©`).
- En cas de problÃ¨me :  
  `RÃ©sultat: Erreur calcul: ...`

---

### ğŸŒ¦ï¸ 2.2. MÃ©tÃ©o mondiale (wttr.in)

Fonctions :

- `tool_weather(city: str)` (asynchrone)
- `tool_weather_sync(city: str)` (synchrone pour Streamlit)

CaractÃ©ristiques :

- Utilise `wttr.in` en mode JSON (`format=j1`).
- Supporte des requÃªtes en texte libre :
  - `meteo rouen`
  - `donne la mÃ©tÃ©o Ã  nantes`
  - `meteo vinci`
- La fonction `_normalize_city_free_text()` :
  - filtre les mots outils (`meteo`, `Ã `, `la`, etc.),
  - rÃ©cupÃ¨re le nom de ville probable,
  - renvoie un nom propre : `Rouen`, `Nantes`, `Vinci`, etc.

Exemple de retour :

```text
Ville: Vinci
TempÃ©rature: 4Â°C
Vent: 22 km/h

### ğŸŒ 2.3. Recherche web (DuckDuckGo)

**Fonction :** `tool_web_search(query: str, max_results: int = 5)`

- Utilise la librairie `ddgs` (DuckDuckGo Search).
- Retourne une **liste JSON** de rÃ©sultats :

```json
[
  {
    "title": "Titre du rÃ©sultat",
    "href": "https://exemple.com",
    "body": "Petit extrait du contenu..."
  }
]

### ğŸ“ 2.4. TODO-list persistante

- **Fichier de stockage :** `todo_store.json`  
- **Fonction principale :** `tool_todo(cmd: str)`

#### Commandes supportÃ©es

**â• Ajouter une tÃ¢che :**

- `ajoute faire les courses`  
- `ajoute : reviser le cours IA`  
- `add reviser le cours rÃ©seaux`  

**âœ… Marquer une tÃ¢che comme terminÃ©e :**

- `termine 2`  
- `done 2`  

**ğŸ“‹ Lister les tÃ¢ches :**

- `liste`  
- `list`  

**ğŸ—‘ï¸ Vider la liste :**

- `efface tout`  
- `reset`  
- `clear`  

Les tÃ¢ches sont stockÃ©es en **JSON**, et `app.py` reformate la rÃ©ponse en liste lisible dans lâ€™interface Streamlit.

## ğŸ’¬ 3. Smalltalk (Ollama)

- **Fichiers concernÃ©s :** `app.py` et `router.py`  

Le smalltalk gÃ¨re les messages du type :

- `bonjour`, `salut`, `coucou`  
- `Ã§a va ?`, `comment tu vas ?`, etc.

`router.py` dÃ©tecte ces formulations et retourne lâ€™intention **`smalltalk`**.

Dans `app.py`, on utilise un modÃ¨le local via `ChatOllama` :

- **ModÃ¨le configurable** via la variable dâ€™environnement `OLLAMA_MODEL`  
  - valeur par dÃ©faut : `llama3.2:3b`
- **Prompt systÃ¨me utilisÃ© :**  
  > "Tu es un assistant amical, bref et poli."

ğŸ“Œ **Important :**  
Ollama **nâ€™est pas utilisÃ© pour le RAG**.  
Il sert uniquement pour la **discussion gÃ©nÃ©rale (smalltalk)**.

## ğŸ“§ 4. Envoi dâ€™e-mail (derniÃ¨re rÃ©ponse)

Dans `app.py` :

- Lâ€™assistant dÃ©tecte des commandes du type :
  - `envoi la reponse Ã  ccolins2010@yahoo.fr`
  - `envoie la rÃ©ponse Ã  mon mail ...`
  - `peux-tu envoyer la rÃ©ponse par email Ã  ...`
- Une adresse e-mail est extraite avec une **regex**, avec correction de petites fautes
  (par exemple : `yahoo;fr` â†’ `yahoo.fr`).
- La fonction `send_email_smtp()` envoie **la derniÃ¨re rÃ©ponse de lâ€™assistant**
  Ã  lâ€™adresse dÃ©tectÃ©e.

Configuration SMTP dans `.env` :

```env
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=ton.email@gmail.com
SMTP_PASS=mot_de_passe_application
SMTP_FROM=ton.email@gmail.com


```markdown
## ğŸ”€ 5. Routage des requÃªtes (app.py + router.py)

La fonction principale `handle_user_query()` dans `app.py` suit cet ordre logique :

1. **RÃ©ponse oui/non aprÃ¨s Ã©chec du RAG**
   - Si on attend une rÃ©ponse Ã   
     > Â« Souhaites-tu que je cherche sur le web ? (oui / non) Â»
   - alors :
     - si lâ€™utilisateur rÃ©pond **oui** â†’ appel Ã  `tool_web_search(...)`
     - si lâ€™utilisateur rÃ©pond **non** â†’ lâ€™assistant reste sur les documents internes.

2. **DÃ©tection dâ€™une commande e-mail**
   - Si la phrase contient une commande du type :  
     `envoi la rÃ©ponse Ã  ...`
   - alors `send_email_smtp()` est appelÃ©.

3. **Ajout du message utilisateur Ã  lâ€™historique**
   - Le message est stockÃ© dans `memory_store.json`.

4. **DÃ©tection rapide de certains cas**
   - Si le texte contient `calcule`, `combien fait`, etc. â†’ `intent = "calc"`
   - Si le texte parle dâ€™**actualitÃ©** ou de  
     `qui est le prÃ©sident ...` â†’ `intent = "web"`

5. **Routage gÃ©nÃ©ral via `router.py`**
   - Si ce nâ€™est pas un cas forcÃ©, `router.py` dÃ©cide de lâ€™intention :
     - `smalltalk`, `weather`, `todo`, `web` ou `rag`.

6. **Si un outil est dÃ©clenchÃ© (calc, mÃ©tÃ©o, todo, web)**
   - `app.py` appelle lâ€™outil correspondant dans `agents.py`,
   - formate la rÃ©ponse,
   - lâ€™affiche,
   - et lâ€™ajoute Ã  lâ€™historique.

7. **Sinon â†’ RAG interne**
   - `answer_question()` est appelÃ© avec la question.
   - Si une section pertinente est trouvÃ©e â†’ on renvoie **lâ€™extrait de cours + la source**.
   - Sinon â†’ on propose :

     > Je nâ€™ai rien trouvÃ© dans les documents internes.  
     > ğŸ‘‰ Souhaites-tu que je cherche sur le web ? (oui / non)

## ğŸ› ï¸ 7. Installation & Lancement

### 7.1. Cloner le projet

```bash
git clone <URL_DU_REPO>
cd projet-ia-assistant-rag-academique

### 7.2. CrÃ©er un environnement virtuel

```bash
python -m venv .venv

### 7.3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt

### 7.4. Configurer Ollama

1. Installer **Ollama** sur ta machine (depuis le site officiel).
2. TÃ©lÃ©charger le modÃ¨le utilisÃ© par lâ€™assistant, puis lancer le serveur :

```bash
ollama pull llama3.2:3b
ollama serve

### 7.5. Configurer le fichier `.env`

CrÃ©er un fichier `.env` Ã  la racine du projet avec le contenu suivant :

```env
# ModÃ¨le utilisÃ© pour le smalltalk (Ollama)
OLLAMA_MODEL=llama3.2:3b

# SMTP pour l'envoi d'e-mails
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=ton.email@gmail.com
SMTP_PASS=mot_de_passe_application
SMTP_FROM=ton.email@gmail.com

### 7.6. Lancer lâ€™application Streamlit

Dans le terminal (en ayant bien activÃ© l'environnement virtuel) :

```bash
streamlit run app.py

Lâ€™interface sera accessible sur : <http://localhost:8501/>

## âœ… 8. Exemples de requÃªtes Ã  tester

Quelques exemples de requÃªtes Ã  essayer dans lâ€™interface :

- `quâ€™est-ce que lâ€™IA ?`
- `BrÃ¨ve histoire de l'IA`
- `câ€™est quoi Python`
- `câ€™est quoi un rÃ©seau informatique`
- `calcule 2Â²+log50`
- `calcule sin45`
- `calcule e4`
- `meteo rouen`
- `meteo vinci`
- `ajoute reviser le cours IA`
- `liste`
- `termine 1`
- `efface tout`
- `qui est le president des USA`
- `actualitÃ© intelligence artificielle`
- `envoi la reponse Ã  monmail@exemple.com`
